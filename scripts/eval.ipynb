{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# gpt-4o-2024-11-20, claude-3-5-sonnet-20241022, gemini-1.5-pro, gpt-4o-mini, deepseek-reasoner...\n",
    "model = \"gpt-4o-2024-11-20\"\n",
    "\n",
    "dataset = \"medxpertqa\"\n",
    "\n",
    "split_list = [\"text\",\"mm\"]\n",
    "\n",
    "full_outputs = []\n",
    "\n",
    "for split in split_list:\n",
    "    if (\"o1\" in model or \"o3\" in model) and (dataset == \"medxpertqa\"):\n",
    "        dataset = \"medxpertqa_sampled\"\n",
    "\n",
    "    if \"qvq\" in model.lower():\n",
    "        prompting_type = \"ao\"\n",
    "    else:\n",
    "        prompting_type = \"cot\"\n",
    "\n",
    "    result_path = f\"outputs/leaderboard/{model}/{dataset}/zero_shot/{prompting_type}/{dataset}_{split}_output.jsonl\"\n",
    "\n",
    "    with open(result_path, \"r\") as f:\n",
    "        outputs = [json.loads(line) for line in f]\n",
    "\n",
    "    # Data Check\n",
    "    source_path = f\"data/{dataset}/input/{dataset}_{split}_input.jsonl\"\n",
    "    with open(source_path, \"r\") as f:\n",
    "        sources = [json.loads(line) for line in f]\n",
    "    assert len(sources) == len(outputs)\n",
    "    for i, source in enumerate(sources):\n",
    "        assert source['id'] == outputs[i]['id']\n",
    "        assert source['question'] == outputs[i]['question']\n",
    "\n",
    "    print(f\"Loaded {len(outputs)} outputs\")\n",
    "    full_outputs.extend(outputs)\n",
    "\n",
    "print(f\"Loaded {len(full_outputs)} full outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(s):\n",
    "    parts = re.split(r'(?i)final answer', s)\n",
    "    return parts\n",
    "\n",
    "if \"qvq\" in model.lower():\n",
    "    print(model)\n",
    "    new_data = []\n",
    "    for index, line in enumerate(tqdm(full_outputs)):\n",
    "        prediction_rationale = line[\"messages\"][-1][\"content\"]\n",
    "\n",
    "        if re.search(r'(?i)final answer', prediction_rationale):\n",
    "            flag = True\n",
    "        else:\n",
    "            flag = False\n",
    "\n",
    "        prediction = split_string(prediction_rationale)[-1].strip()\n",
    "\n",
    "        if line['id'].lower().startswith(\"text\"):\n",
    "            u_pattern = r\"[A-J]\"\n",
    "            l_pattern = r\"[a-j]\"\n",
    "        else:\n",
    "            u_pattern = r\"[A-E]\"\n",
    "            l_pattern = r\"[a-e]\"\n",
    "\n",
    "        letter_match = re.findall(u_pattern, prediction)\n",
    "        if letter_match:\n",
    "            if flag:\n",
    "                prediction = letter_match[0]\n",
    "            else:\n",
    "                prediction = letter_match[-1]\n",
    "        else:\n",
    "            letter_match = re.findall(l_pattern, prediction)\n",
    "            if letter_match:\n",
    "                if flag:\n",
    "                    prediction = letter_match[0].upper()\n",
    "                else:\n",
    "                    prediction = letter_match[-1].upper()\n",
    "\n",
    "        label = line[\"label\"][0]\n",
    "        line[\"prediction\"] = prediction\n",
    "        line[\"correct\"] = prediction == label\n",
    "        new_data.append(line)\n",
    "    full_outputs = new_data\n",
    "elif model == \"deepseek-reasoner\":\n",
    "    print(model)\n",
    "    new_data = []\n",
    "    for index, line in enumerate(tqdm(full_outputs)):\n",
    "        assert \"Put your final\" in line['messages'][-2][\"content\"]\n",
    "\n",
    "        prediction = line['response']\n",
    "\n",
    "        if line['id'].lower().startswith(\"text\"):\n",
    "            pattern = r\"\\\\boxed{([A-J])}\"\n",
    "        else:\n",
    "            pattern = r\"\\\\boxed{([A-E])}\"\n",
    "\n",
    "        letter_match = re.findall(pattern, prediction)\n",
    "        prediction = letter_match[0] if letter_match else prediction\n",
    "        label = line['label'][0]\n",
    "        line[\"prediction\"] = prediction\n",
    "        line[\"correct\"] = prediction == label\n",
    "        new_data.append(line)\n",
    "    full_outputs = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results stats\n",
    "types = set([output['question_type'] for output in full_outputs])\n",
    "types = sorted(list(types))\n",
    "print(f\"Types: {types}\")\n",
    "\n",
    "print(\"------------------- Main Results -------------------\")\n",
    "print(f\"Model: {model}\")\n",
    "\n",
    "print()\n",
    "for split in split_list:\n",
    "    for type in types:\n",
    "        correct = sum([output['correct'] == True for output in full_outputs if output['question_type'] == type and output['id'].lower().startswith(split)])\n",
    "        total = sum([output['question_type'] == type and output['id'].lower().startswith(split) for output in full_outputs])\n",
    "        print(f\"Split: {split}, Type: {type}, Correct: {correct}, Total: {total}, Accuracy: {correct/total:.2%}\")\n",
    "    correct = sum([output['correct'] == True for output in full_outputs if output['id'].lower().startswith(split)])\n",
    "    total = sum([output['id'].lower().startswith(split) for output in full_outputs])\n",
    "    print(f\"Split: {split}, Correct: {correct}, Total: {total}, Accuracy: {correct / total:.2%}\")\n",
    "    print()\n",
    "\n",
    "for type in types:\n",
    "    correct = sum([output['correct'] == True for output in full_outputs if output['question_type'] == type])\n",
    "    total = sum([output['question_type'] == type for output in full_outputs])\n",
    "    print(f\"Type: {type}, Correct: {correct}, Total: {total}, Accuracy: {correct/total:.2%}\")\n",
    "\n",
    "print()\n",
    "correct_full = sum([output['correct'] == True for output in full_outputs])\n",
    "total_full = len(full_outputs)\n",
    "print(f\"Correct Full: {correct_full}, Total Full: {total_full}, Accuracy: {correct_full / total_full:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
